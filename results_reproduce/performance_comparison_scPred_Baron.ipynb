{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: Matrix\n",
      "\n",
      "Warning message in asMethod(object):\n",
      "“sparse->dense coercion: allocating vector of size 1.3 GiB”\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#read data\n",
    "\n",
    "BaronMatrix   <- readRDS(url(\"https://storage.googleapis.com/cellid-cbl/BaronMatrix.rds\"))\n",
    "BaronMetaData <- readRDS(url(\"https://storage.googleapis.com/cellid-cbl/BaronMetaData.rds\"))\n",
    "\n",
    "data=t(as.matrix(BaronMatrix))\n",
    "annotation=BaronMetaData\n",
    "\n",
    "annotation$celltype=annotation$cell.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "extract_prediction_label = function(x){\n",
    "    y=c()\n",
    "    for (i in x){\n",
    "        y=c(y,i)\n",
    "    }\n",
    "    y\n",
    "    return(y)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "calculate_test_accuracy <- function(true_labels, predicted_labels) {\n",
    "  if (length(true_labels) != length(predicted_labels)) {\n",
    "    stop(\"Input vectors must have the same length.\")\n",
    "  }\n",
    "  \n",
    "  correct_predictions <- sum(true_labels == predicted_labels)\n",
    "  total_samples <- length(true_labels)\n",
    "  \n",
    "  accuracy <- correct_predictions / total_samples\n",
    "  return(accuracy)\n",
    "}\n",
    "\n",
    "\n",
    "calculate_f1_score_multiclass <- function(true_labels, predicted_labels) {\n",
    "  if (length(true_labels) != length(predicted_labels)) {\n",
    "    stop(\"Input vectors must have the same length.\")\n",
    "  }\n",
    "  \n",
    "  # Get unique class labels\n",
    "  classes <- unique(c(true_labels, predicted_labels))\n",
    "  \n",
    "  # Initialize variables to store per-class statistics\n",
    "  precision <- numeric(length(classes))\n",
    "  recall <- numeric(length(classes))\n",
    "  f1_score <- numeric(length(classes))\n",
    "  \n",
    "  # Calculate precision, recall, and F1 score for each class\n",
    "  for (i in 1:length(classes)) {\n",
    "    class_label <- classes[i]\n",
    "    true_positive <- sum(predicted_labels == class_label & true_labels == class_label)\n",
    "    false_positive <- sum(predicted_labels == class_label & true_labels != class_label)\n",
    "    false_negative <- sum(predicted_labels != class_label & true_labels == class_label)\n",
    "    \n",
    "    precision[i] <- true_positive / (true_positive + false_positive)\n",
    "    recall[i] <- true_positive / (true_positive + false_negative)\n",
    "    \n",
    "    f1_score[i] <- 2 * (precision[i] * recall[i]) / (precision[i] + recall[i])\n",
    "  }\n",
    "  \n",
    "  # Calculate macro-averaged F1 score\n",
    "  macro_f1_score <- mean(f1_score, na.rm = TRUE)\n",
    "  \n",
    "  return(macro_f1_score)\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attaching SeuratObject\n",
      "\n",
      "Warning message in split.default(sample(nrow(data)), 1:num_folds):\n",
      "“data length is not a multiple of split variable”\n",
      "Warning message:\n",
      "“The default method for RunUMAP has changed from calling Python UMAP via reticulate to the R-native UWOT using the cosine metric\n",
      "To use Python UMAP via reticulate, set umap.method to 'umap-learn' and metric to 'correlation'\n",
      "This message will be shown once per session”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m●  Extracting feature space for each cell type...\n",
      "\u001b[39m\u001b[32mDONE!\n",
      "\u001b[39m\u001b[32m●  Training models for each cell type...\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: ggplot2\n",
      "\n",
      "Loading required package: lattice\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mDONE!\n",
      "\u001b[39m\u001b[32m●  Matching reference with new dataset...\n",
      "\u001b[39m\u001b[36m\t ─ 2000 features present in reference loadings\n",
      "\u001b[39m\u001b[36m\t ─ 2000 features shared between reference and new dataset\n",
      "\u001b[39m\u001b[36m\t ─ 100% of features in the reference are present in new dataset\n",
      "\u001b[39m\u001b[32m●  Aligning new data to reference...\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 1/20\n",
      "\n",
      "Harmony 2/20\n",
      "\n",
      "Harmony 3/20\n",
      "\n",
      "Harmony converged after 3 iterations\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m●  Classifying cells...\n",
      "\u001b[39m\u001b[32mDONE!\n",
      "\u001b[39mFold 1 : Train samples = 6855 , Test samples = 1714 Accuracy: 0.9801634 f1 score: 0.9327988 \n",
      "\u001b[32m●  Extracting feature space for each cell type...\n",
      "\u001b[39m\u001b[32mDONE!\n",
      "\u001b[39m\u001b[32m●  Training models for each cell type...\n",
      "\u001b[39m\u001b[32mDONE!\n",
      "\u001b[39m\u001b[32m●  Matching reference with new dataset...\n",
      "\u001b[39m\u001b[36m\t ─ 2000 features present in reference loadings\n",
      "\u001b[39m\u001b[36m\t ─ 2000 features shared between reference and new dataset\n",
      "\u001b[39m\u001b[36m\t ─ 100% of features in the reference are present in new dataset\n",
      "\u001b[39m\u001b[32m●  Aligning new data to reference...\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 1/20\n",
      "\n",
      "Harmony 2/20\n",
      "\n",
      "Harmony 3/20\n",
      "\n",
      "Harmony 4/20\n",
      "\n",
      "Harmony converged after 4 iterations\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m●  Classifying cells...\n",
      "\u001b[39m\u001b[32mDONE!\n",
      "\u001b[39mFold 2 : Train samples = 6855 , Test samples = 1714 Accuracy: 0.9784131 f1 score: 0.973887 \n",
      "\u001b[32m●  Extracting feature space for each cell type...\n",
      "\u001b[39m\u001b[32mDONE!\n",
      "\u001b[39m\u001b[32m●  Training models for each cell type...\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
      "“There were missing values in resampled performance measures.”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mDONE!\n",
      "\u001b[39m\u001b[32m●  Matching reference with new dataset...\n",
      "\u001b[39m\u001b[36m\t ─ 2000 features present in reference loadings\n",
      "\u001b[39m\u001b[36m\t ─ 2000 features shared between reference and new dataset\n",
      "\u001b[39m\u001b[36m\t ─ 100% of features in the reference are present in new dataset\n",
      "\u001b[39m\u001b[32m●  Aligning new data to reference...\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 1/20\n",
      "\n",
      "Harmony 2/20\n",
      "\n",
      "Harmony 3/20\n",
      "\n",
      "Harmony 4/20\n",
      "\n",
      "Harmony converged after 4 iterations\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m●  Classifying cells...\n",
      "\u001b[39m\u001b[32mDONE!\n",
      "\u001b[39mFold 3 : Train samples = 6855 , Test samples = 1714 Accuracy: 0.9848308 f1 score: 0.9034316 \n",
      "\u001b[32m●  Extracting feature space for each cell type...\n",
      "\u001b[39m\u001b[32mDONE!\n",
      "\u001b[39m\u001b[32m●  Training models for each cell type...\n",
      "\u001b[39m\u001b[32mDONE!\n",
      "\u001b[39m\u001b[32m●  Matching reference with new dataset...\n",
      "\u001b[39m\u001b[36m\t ─ 2000 features present in reference loadings\n",
      "\u001b[39m\u001b[36m\t ─ 2000 features shared between reference and new dataset\n",
      "\u001b[39m\u001b[36m\t ─ 100% of features in the reference are present in new dataset\n",
      "\u001b[39m\u001b[32m●  Aligning new data to reference...\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 1/20\n",
      "\n",
      "Harmony 2/20\n",
      "\n",
      "Harmony 3/20\n",
      "\n",
      "Harmony 4/20\n",
      "\n",
      "Harmony converged after 4 iterations\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m●  Classifying cells...\n",
      "\u001b[39m\u001b[32mDONE!\n",
      "\u001b[39mFold 4 : Train samples = 6855 , Test samples = 1714 Accuracy: 0.9848308 f1 score: 0.9902553 \n",
      "\u001b[32m●  Extracting feature space for each cell type...\n",
      "\u001b[39m\u001b[32mDONE!\n",
      "\u001b[39m\u001b[32m●  Training models for each cell type...\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
      "“There were missing values in resampled performance measures.”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mDONE!\n",
      "\u001b[39m\u001b[32m●  Matching reference with new dataset...\n",
      "\u001b[39m\u001b[36m\t ─ 2000 features present in reference loadings\n",
      "\u001b[39m\u001b[36m\t ─ 2000 features shared between reference and new dataset\n",
      "\u001b[39m\u001b[36m\t ─ 100% of features in the reference are present in new dataset\n",
      "\u001b[39m\u001b[32m●  Aligning new data to reference...\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Harmony 1/20\n",
      "\n",
      "Harmony 2/20\n",
      "\n",
      "Harmony 3/20\n",
      "\n",
      "Harmony 4/20\n",
      "\n",
      "Harmony converged after 4 iterations\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m●  Classifying cells...\n",
      "\u001b[39m\u001b[32mDONE!\n",
      "\u001b[39mFold 5 : Train samples = 6856 , Test samples = 1713 Accuracy: 0.9801518 f1 score: 0.9678119 \n"
     ]
    }
   ],
   "source": [
    "library(Seurat)\n",
    "library(scPred)\n",
    "set.seed(124)\n",
    "\n",
    "\n",
    "num_folds <- 5\n",
    "\n",
    "# Generate 5-fold cross-validation indices\n",
    "fold_indices <- split(sample(nrow(data)), 1:num_folds)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "for (i in 1:num_folds) {\n",
    "  # Get indices for the current fold\n",
    "  test_indices <- fold_indices[[i]]\n",
    "  train_indices <- unlist(fold_indices[-i])\n",
    "  \n",
    "  # Subset data and annotation based on indices\n",
    "  data_train <- data[train_indices, ]\n",
    "  anno_train <- annotation[train_indices, ]\n",
    "  \n",
    "  data_test <- data[test_indices, ]\n",
    "  anno_test <- annotation[test_indices, ]\n",
    "  \n",
    "  \n",
    "  reference = CreateSeuratObject(counts = t(data_train))\n",
    "  query = CreateSeuratObject(counts = t(data_test))\n",
    "  \n",
    "  reference=NormalizeData(reference, verbose = FALSE)\n",
    "  reference=FindVariableFeatures(reference, selection.method = \"vst\", nfeatures = 2000)\n",
    "  reference=ScaleData(reference, verbose = FALSE)\n",
    "  reference=RunPCA(reference, verbose = FALSE)\n",
    "  reference=RunUMAP(reference, reduction = \"pca\", dims = 1:30, verbose = FALSE)\n",
    "  \n",
    "\n",
    "  reference$celltype=anno_train$celltype\n",
    " \n",
    "  reference <- getFeatureSpace(reference, \"celltype\")\n",
    "\n",
    "  reference <- trainModel(reference)\n",
    "\n",
    "  query <- NormalizeData(query)\n",
    "  query <- scPredict(query, reference)\n",
    "\n",
    "  predictions=extract_prediction_label(query$scpred_prediction)\n",
    "\n",
    "  acc=calculate_test_accuracy(anno_test$celltype,predictions)\n",
    "\n",
    "\n",
    "  f1_score = calculate_f1_score_multiclass(anno_test$celltype,predictions)\n",
    "\n",
    "\n",
    "  cat(\"Fold\", i, \": Train samples =\", nrow(data_train), \", Test samples =\", nrow(data_test), \"Accuracy:\", acc,\"f1 score:\",f1_score, \"\\n\")\n",
    "\n",
    "  \n",
    "  # Perform training and testing using data_train, anno_train, data_test, and anno_test\n",
    "}\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
